{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_BUCKET = \"raw-data\"\n",
    "AWS_REGION = \"us-east-1\"\n",
    "ENDPOINT_URL = \"http://localhost:4566\" # LocalStack endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\", endpoint_url=ENDPOINT_URL, region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = \"raw-data\"\n",
    "processed_bucket = \"processed-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_objects = s3.list_objects_v2(Bucket=raw_data).get(\"Contents\", [])\n",
    "csv_files = [obj[\"Key\"] for obj in csv_objects if obj[\"Key\"] != \"population_data.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataframes = []\n",
    "for key in csv_files:\n",
    "    obj = s3.get_object(Bucket=raw_data, Key=key)\n",
    "    df = pd.read_csv(obj[\"Body\"])\n",
    "    csv_dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not csv_dataframes:\n",
    "    print(\"No CSV files found in raw bucket.\")\n",
    "    csv_df = pd.DataFrame()\n",
    "else:\n",
    "    csv_df = pd.concat(csv_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_objects = s3.list_objects_v2(Bucket=processed_bucket).get(\"Contents\", [])\n",
    "json_files = [obj[\"Key\"] for obj in json_objects if obj[\"Key\"].endswith(\".json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dataframes = []\n",
    "for key in json_files:\n",
    "    obj = s3.get_object(Bucket=processed_bucket, Key=key)\n",
    "    json_content = json.load(obj[\"Body\"])\n",
    "    json_df = pd.DataFrame(json_content)\n",
    "    json_dataframes.append(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not json_dataframes:\n",
    "    print(\"No JSON files found in processed bucket.\")\n",
    "    json_df = pd.DataFrame()\n",
    "else:\n",
    "    json_df = pd.concat(json_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not json_df.empty:\n",
    "    pop_df = json_df.copy()\n",
    "    pop_df = pop_df[(pop_df[\"year\"] >= 2013) & (pop_df[\"year\"] <= 2018)]\n",
    "    mean_population = pop_df[\"population\"].mean()\n",
    "    std_population = pop_df[\"population\"].std()\n",
    "    print(f\"Mean population (2013-2018): {mean_population}\")\n",
    "    print(f\"Std deviation (2013-2018): {std_population}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not csv_df.empty:\n",
    "    csv_df['value'] = pd.to_numeric(csv_df['value'], errors='coerce')\n",
    "    csv_df['year'] = pd.to_numeric(csv_df['year'], errors='coerce')\n",
    "    best_years = csv_df.groupby('series_id').apply(\n",
    "        lambda x: x.groupby('year')['value'].sum().idxmax()\n",
    "    ).reset_index(name='best_year')\n",
    "\n",
    "    # Add summed value for best year\n",
    "    best_years['sum_value'] = best_years.apply(\n",
    "        lambda row: csv_df[(csv_df['series_id'] == row['series_id']) & (csv_df['year'] == row['best_year'])][\n",
    "            'value'].sum(),\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Best year per series_id with summed value:\")\n",
    "    print(best_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not csv_df.empty and not json_df.empty:\n",
    "    combined_df = csv_df[(csv_df['series_id'] == 'PRS30006032') & (csv_df['period'] == 'Q01')]\n",
    "    combined_df = combined_df.merge(json_df[['year', 'population']], on='year', how='left')\n",
    "    print(\"Combined report for PRS30006032, period Q01:\")\n",
    "    print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
